{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import library yang digunakan"
      ],
      "metadata": {
        "id": "HaWZuuf9ar4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxsmEHsTNc_J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Dataset"
      ],
      "metadata": {
        "id": "RyppTB7xbB5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset CSV\n",
        "df = pd.read_csv(\"DataDestinasi.csv\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "vH_JIxMDa_En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kodingan mengubah column price pada dataset\n",
        "jika dibawah harga di bawah 20000 akan dilakukan mix dengan range, [5000, 10000, 15000, 20000]"
      ],
      "metadata": {
        "id": "tdJTRLf3bxet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5GgvH7YNfyj",
        "outputId": "c7ee2472-aa01-4810-d7be-282f8cc49ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah nilai 0 pada kolom 'Price' sebelum diganti: 168\n",
            "Jumlah nilai 0 pada kolom 'Price' setelah diganti: 0\n"
          ]
        }
      ],
      "source": [
        "df['Price'] = pd.to_numeric(df['Price'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "print(\"Jumlah nilai 0 pada kolom 'Price' sebelum diganti:\", (df['Price'] <= 20000).sum())\n",
        "\n",
        "replacement_values = [5000, 10000, 15000, 20000]\n",
        "\n",
        "df['Price'] = df['Price'].apply(lambda x: np.random.choice(replacement_values) if x == 0 else x)\n",
        "\n",
        "print(\"Jumlah nilai 0 pada kolom 'Price' setelah diganti:\", (df['Price'] <= 20000).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tranform pada column \"Price\", \"Place_Name\"\n",
        "Dan menggunakan 2 layers dengan hyperparameter 128, 64\n",
        "dengan aktivation softmax pada layers output"
      ],
      "metadata": {
        "id": "pcxsLcydcxJv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXgaPnTqKYcd",
        "outputId": "e101010f-b8ea-4c07-97a3-0db4a3949b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 6.3340\n",
            "Epoch 2/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 9.1996e-04 - loss: 6.3136\n",
            "Epoch 3/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0077 - loss: 6.2664\n",
            "Epoch 4/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0234 - loss: 6.1707\n",
            "Epoch 5/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0155 - loss: 5.9984\n",
            "Epoch 6/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0344 - loss: 5.6654\n",
            "Epoch 7/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0259 - loss: 5.2804\n",
            "Epoch 8/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0448 - loss: 4.8542\n",
            "Epoch 9/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0362 - loss: 4.5815\n",
            "Epoch 10/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0483 - loss: 4.3462\n",
            "Epoch 11/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0285 - loss: 4.1873\n",
            "Epoch 12/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0647 - loss: 4.0440\n",
            "Epoch 13/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0556 - loss: 4.0193\n",
            "Epoch 14/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0769 - loss: 3.8799\n",
            "Epoch 15/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0876 - loss: 3.8663\n",
            "Epoch 16/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0526 - loss: 3.8551 \n",
            "Epoch 17/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0835 - loss: 3.7632 \n",
            "Epoch 18/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0650 - loss: 3.7615\n",
            "Epoch 19/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0902 - loss: 3.6418 \n",
            "Epoch 20/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0760 - loss: 3.6179 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "df['Price_scaled'] = scaler.fit_transform(df[['Price']])\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['Place_Label'] = label_encoder.fit_transform(df['Place_Name'])\n",
        "\n",
        "city_encoder = OneHotEncoder(sparse_output=False)\n",
        "city_encoded = city_encoder.fit_transform(df[['City']])\n",
        "\n",
        "X_price_city = np.hstack([df['Price_scaled'].values.reshape(-1, 1), city_encoded])\n",
        "\n",
        "place_labels = df['Place_Label'].values\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.InputLayer(shape=(X_price_city.shape[1],)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(len(df['Place_Name'].unique()), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_price_city, place_labels, epochs=20, batch_size=32)\n",
        "\n",
        "model.save(\"model_destinasi_wisata.h5\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat function recommend_places"
      ],
      "metadata": {
        "id": "Pw4ZpgLVdE1o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZy_sfSmkbIO"
      },
      "outputs": [],
      "source": [
        "def recommend_places(price, city, top_n=5):\n",
        "    price_scaled = scaler.transform(np.array([[price]]))\n",
        "    city_encoded = city_encoder.transform(np.array([[city]]))\n",
        "    user_input = np.hstack([price_scaled, city_encoded])\n",
        "\n",
        "    probabilities = model.predict(user_input)[0]\n",
        "\n",
        "    top_indices = np.argsort(probabilities)[-top_n:][::-1]\n",
        "\n",
        "    recommended_places = label_encoder.inverse_transform(top_indices)\n",
        "    return recommended_places\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membuat alternative function recommended_tour_guid"
      ],
      "metadata": {
        "id": "v6_SeoLcd-Do"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxdmoewnkjSi"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "# Fungsi untuk merekomendasikan destinasi berdasarkan budget\n",
        "def recommend_tour_guide(budget, city):\n",
        "    # Filter destinasi berdasarkan kota\n",
        "    city_places = df[df['City'] == city]\n",
        "\n",
        "    # Mengambil data nama dan harga\n",
        "    places = list(zip(city_places['Place_Name'], city_places['Price']))\n",
        "\n",
        "    best_combination = []\n",
        "    max_cost = 0\n",
        "\n",
        "    # Menggunakan kombinasi untuk mencari 3 destinasi\n",
        "    for combo in combinations(places, 3):\n",
        "        total_cost = sum(price for _, price in combo)\n",
        "        if total_cost <= budget and total_cost > max_cost:\n",
        "            max_cost = total_cost\n",
        "            best_combination = combo\n",
        "\n",
        "    return best_combination, max_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contoh penggunaan function"
      ],
      "metadata": {
        "id": "0HYz0_1FeFYo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzNcC2gUKrAC",
        "outputId": "61a814a9-e285-48c3-c7ec-0c44edc42c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Rekomendasi untuk anggaran 100000 di kota Bekasi:\n",
            "1. Trans Snow World Juanda\n",
            "2. Go! Wet Waterpark\n",
            "3. Waterboom Lippo Cikarang\n",
            "4. Mountain View Golf Club\n",
            "5. Trans Studio Bandung\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Contoh penggunaan\n",
        "user_budget = 100000  # Anggaran pengguna\n",
        "user_city = 'Bekasi'  # Kota yang diminta pengguna\n",
        "recommended_places = recommend_places(user_budget, user_city)\n",
        "\n",
        "print(f\"Rekomendasi untuk anggaran {user_budget} di kota {user_city}:\")\n",
        "for i, place in enumerate(recommended_places, 1):\n",
        "    print(f\"{i}. {place}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ym3D6_lkqA",
        "outputId": "2ca9207a-d4a9-40bd-cba8-543bba2a05f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rekomendasi untuk anggaran 30000 di kota Cilegon:\n",
            "1. Pantai Batu Saung - Harga: 10000\n",
            "2. Bukit Kembang Kuning - Harga: 5000\n",
            "3. Masjid Agung Cilegon - Harga: 15000\n",
            "Total biaya: 30000\n"
          ]
        }
      ],
      "source": [
        "# Contoh penggunaan\n",
        "user_budget = 30000  # Anggaran pengguna\n",
        "user_city = 'Cilegon'  # Kota yang diminta pengguna\n",
        "recommended_places, total_cost = recommend_tour_guide(user_budget, user_city)\n",
        "\n",
        "print(f\"Rekomendasi untuk anggaran {user_budget} di kota {user_city}:\")\n",
        "for i, (place, price) in enumerate(recommended_places, 1):\n",
        "    print(f\"{i}. {place} - Harga: {price}\")\n",
        "print(f\"Total biaya: {total_cost}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "79j5Z6aweMXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('model_destinasi_wisata.h5')\n",
        "model.predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn9P1VuGUXgl",
        "outputId": "899a0cdc-9dfb-4fde-d614-85e1105eb5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yCinjJOInd_9",
        "outputId": "16daa6b6-064e-4a42-86df-6a1ef4c54e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.22.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.8.5)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (6.4.5)\n",
            "Requirement already satisfied: jax>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.13 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.33)\n",
            "Requirement already satisfied: tensorflow<3,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.17.1)\n",
            "Requirement already satisfied: tf-keras>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.17.0)\n",
            "Collecting tensorflow-decision-forests>=1.5.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: six<2,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.16.1)\n",
            "Collecting packaging~=23.1 (from tensorflowjs)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.26.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (0.1.68)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->tensorflowjs) (6.0.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.13->tensorflowjs) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\n",
            "Collecting tensorflow<3,>=2.13.0 (from tensorflowjs)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.45.0)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.5.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ydf (from tensorflow-decision-forests>=1.5.0->tensorflowjs)\n",
            "  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<3,>=2.13.0->tensorflowjs)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.13.0 (from tensorflowjs)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<3,>=2.13.0->tensorflowjs) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.1.3)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.87)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.2->tensorflowjs) (1.10.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2024.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2024.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.21.0)\n",
            "Downloading tensorflowjs-4.22.0-py3-none-any.whl (89 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Downloading tensorflow_decision_forests-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ydf, wurlitzer, packaging, tensorboard, tensorflow, tf-keras, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "Successfully installed packaging-23.2 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-decision-forests-1.11.0 tensorflowjs-4.22.0 tf-keras-2.18.0 wurlitzer-3.1.1 ydf-0.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "34ed793e61184b59866e391187335f74"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pjHzRjPnIMOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=keras model_destinasi_wisata.h5 ./model_directory\n"
      ],
      "metadata": {
        "id": "AgYHsK1pK7MH",
        "outputId": "d31f0325-0f9c-44d9-f0f2-ce37c10d833b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-20 15:25:48.445791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1732116348.488979   26370 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1732116348.502085   26370 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[32mğŸŒ² Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
            "failed to lookup keras version from the file,\n",
            "    this is likely a weight only file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01F7qXtUnzsI",
        "outputId": "9f15d94c-2454-4308-de44-e8898153b1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-20 10:42:01.470944: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1732099321.494818   10355 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1732099321.502472   10355 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[32mğŸŒ² Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
            "failed to lookup keras version from the file,\n",
            "    this is likely a weight only file\n"
          ]
        }
      ],
      "source": [
        "!tensorflowjs_converter --input_format=keras model_destinasi_wisata.h5 \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NKCzaO0mAHu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "# Fungsi untuk merekomendasikan destinasi berdasarkan budget\n",
        "def recommend_tour_guide(budget, city):\n",
        "    # Filter destinasi berdasarkan kota\n",
        "    city_places = df[df['City'] == city]\n",
        "\n",
        "    # Mengambil data nama dan harga\n",
        "    places = list(zip(city_places['Place_Name'], city_places['Price']))\n",
        "    place_labels = city_places['Place_Label'].values\n",
        "\n",
        "    # Siapkan input untuk model\n",
        "    price_scaled = scaler.transform(np.array([[budget]]))\n",
        "    city_encoded = city_encoder.transform(np.array([[city]]))\n",
        "    user_input = np.hstack([price_scaled, city_encoded])\n",
        "\n",
        "    # Dapatkan probabilitas dari model\n",
        "    probabilities = model.predict(user_input)[0]\n",
        "\n",
        "    # Menggabungkan nama, harga, dan probabilitas\n",
        "    scored_places = list(zip(places, probabilities))\n",
        "\n",
        "    # Mengurutkan berdasarkan probabilitas\n",
        "    scored_places.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    best_combination = []\n",
        "    max_cost = 0\n",
        "\n",
        "    # Menggunakan kombinasi untuk mencari 3 destinasi\n",
        "    for combo in combinations(scored_places, 3):\n",
        "        total_cost = sum(price for (_, price), _ in combo)\n",
        "        if total_cost <= budget and total_cost > max_cost:\n",
        "            max_cost = total_cost\n",
        "            best_combination = combo\n",
        "\n",
        "    return [(place[0][0], place[0][1]) for place in best_combination], max_cost"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}